{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc9f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c63c5",
   "metadata": {},
   "source": [
    "The main idea behind this model is:\n",
    "\n",
    "1. find `N` similar `(brand, region)` in the train dataset using the `brand_3`, `brand_3_market` and `brand_12_market` features.\n",
    "2. compute the `mean` and the `std` deviation of these `N` groups\n",
    "3. predict `(mean - X * std, mean + X * std)`, where `X ~ 1.2815`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e231620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS \n",
    "N = 5\n",
    "X = 1.2815"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f34703",
   "metadata": {},
   "source": [
    "# 1 - read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7266ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_data_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8928ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/data_split/train'\n",
    "train_data = get_data_from_path(train_path)\n",
    "\n",
    "val_path = '../data/data_split/val'\n",
    "val_data = get_data_from_path(val_path)\n",
    "\n",
    "test_path = '../data/data_split/test'\n",
    "test_data = get_data_from_path(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aade173",
   "metadata": {},
   "source": [
    "# 2 - correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c4265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aeb66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['month', 'region']\n",
    "correlation_features = ['brand_3', 'brand_3_market', 'brand_12_market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bce0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales = train_data['sales_train']\n",
    "val_sales = val_data['sales_train']\n",
    "test_sales = test_data['sales_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7057df68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivoted_train_sales = pd.pivot(train_sales, index=index,columns='brand', values='sales').reset_index()\n",
    "pivoted_val_sales = pd.pivot(val_sales, index=index,columns='brand', values='sales').reset_index()\n",
    "pivoted_test_sales = pd.pivot(test_sales, index=index,columns='brand', values='sales').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57830bbe",
   "metadata": {},
   "source": [
    "## 2.1 - datasets for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c84228b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_dict(A: pd.DataFrame, B: pd.DataFrame, n: int):\n",
    "    d = dict()\n",
    "    for a_group, a_group_data in A.groupby('region'):\n",
    "        tmp = dict()\n",
    "        d[a_group] = dict()\n",
    "        for b_group, b_group_data in B.groupby('region'):\n",
    "            if a_group == b_group:\n",
    "                continue\n",
    "            corrs = []\n",
    "            for cf in correlation_features:\n",
    "                c = np.corrcoef(a_group_data[cf], b_group_data[cf])[0][1]\n",
    "                corrs.append(c)\n",
    "            tmp[b_group] = np.mean(corrs)\n",
    "            \n",
    "        d[a_group] = sorted(tmp, reverse=True, key = lambda x: tmp[x])[:n]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35899b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'percentile_%s' % n\n",
    "    return percentile_\n",
    "\n",
    "FEATURES = ('mean', 'std', percentile(10), percentile(90), 'min', 'max')\n",
    "\n",
    "def get_features_using_correlations(train, test, corrs):\n",
    "    test_features = []\n",
    "    for region, region_data in test.groupby(['region']):\n",
    "        x = train[train['region'].isin(corrs[region])].groupby('month').agg({'brand_1': FEATURES,\n",
    "                                                                             'brand_2': FEATURES})\n",
    "        for _, c in x.columns:\n",
    "            region_data[f'brand_1_similar_{c}'] = x['brand_1'][c].values\n",
    "            region_data[f'brand_2_similar_{c}'] = x['brand_2'][c].values\n",
    "            \n",
    "        test_features.append(region_data)\n",
    "    return pd.concat(test_features).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc92836b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset to train the validation model\n",
    "A = pivoted_train_sales.copy()\n",
    "B = pivoted_train_sales.copy()\n",
    "corr_dict_train = get_correlation_dict(A, B, n=N)\n",
    "validation_train_features = get_features_using_correlations(train=A, test=B, corrs=corr_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3225556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to test the validation model\n",
    "A = pivoted_val_sales.copy()\n",
    "B = pivoted_train_sales.copy()\n",
    "corr_dict_val = get_correlation_dict(A, B, n=N)\n",
    "validation_test_features = get_features_using_correlations(train=B, test=A, corrs=corr_dict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5f8864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['brand_1', 'brand_12_market', 'brand_2', 'brand_3', 'brand_3_market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fa421c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_train_features.drop(to_drop, axis=1).to_csv(\"train_for_validation.csv\", index=False)\n",
    "validation_test_features.drop(to_drop, axis=1).to_csv(\"test_for_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34796b18",
   "metadata": {},
   "source": [
    "## 2.2 - dataset for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "db3055f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset to train the test model\n",
    "A = pd.concat([pivoted_train_sales, pivoted_val_sales])\n",
    "B = pd.concat([pivoted_train_sales, pivoted_val_sales])\n",
    "corr_dict_train = get_correlation_dict(A, B, n=N)\n",
    "train_train_features = get_features_using_correlations(train=A, test=B, corrs=corr_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4507c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to test the test model\n",
    "A = pivoted_test_sales.copy()\n",
    "B = pd.concat([pivoted_train_sales, pivoted_val_sales])\n",
    "corr_dict_test = get_correlation_dict(A, B, n=N)\n",
    "train_test_features = get_features_using_correlations(train=B, test=A, corrs=corr_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5243dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['brand_12_market', 'brand_3', 'brand_3_market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0a501924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_train_features.drop(to_drop, axis=1).to_csv(\"train_for_test.csv\", index=False)\n",
    "train_test_features.drop(to_drop, axis=1).to_csv(\"test_for_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd2294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
