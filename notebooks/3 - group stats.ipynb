{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd440aa0",
   "metadata": {},
   "source": [
    "The idea here is to find regions with similar GDPS and number of healthcare workers and get from there the average sales per brand 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09daf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec7909",
   "metadata": {},
   "source": [
    "# 1 - read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47d0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_data_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487f9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/data_split/train'\n",
    "train_data = get_data_from_path(train_path)\n",
    "\n",
    "val_path = '../data/data_split/val'\n",
    "val_data = get_data_from_path(val_path)\n",
    "\n",
    "test_path = '../data/data_split/test'\n",
    "test_data = get_data_from_path(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f257d90",
   "metadata": {},
   "source": [
    "# 2 - groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaeea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fb85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_regions = train_data['regions']\n",
    "train_regions_hcps = train_data['regions_hcps']\n",
    "\n",
    "train_regions_data = train_regions.merge(train_regions_hcps)\n",
    "train_sales = train_data['sales_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f133b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_regions = val_data['regions']\n",
    "val_regions_hcps = val_data['regions_hcps']\n",
    "\n",
    "val_regions_data = val_regions.merge(val_regions_hcps)\n",
    "val_sales = val_data['sales_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f559a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regions = test_data['regions']\n",
    "test_regions_hcps = test_data['regions_hcps']\n",
    "\n",
    "test_regions_data = test_regions.merge(test_regions_hcps)\n",
    "test_sales = test_data['sales_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25eea71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_regions_data['total_hcps'] = train_regions_data[['Internal medicine', 'Internal medicine / pneumology',\n",
    "                                             'General practicioner', 'Internal medicine and general practicioner',\n",
    "                                             'Pediatrician']].sum(axis=1)\n",
    "val_regions_data['total_hcps'] = val_regions_data[['Internal medicine', 'Internal medicine / pneumology',\n",
    "                                         'General practicioner', 'Internal medicine and general practicioner',\n",
    "                                         'Pediatrician']].sum(axis=1)\n",
    "\n",
    "test_regions_data['total_hcps'] = test_regions_data[['Internal medicine', 'Internal medicine / pneumology',\n",
    "                                         'General practicioner', 'Internal medicine and general practicioner',\n",
    "                                         'Pediatrician']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a73450a",
   "metadata": {},
   "source": [
    "## 2.1 - datasets for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9f5879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here the groups are generated for different features \n",
    "feats_to_group = ['pci16', 'pci18', 'Internal medicine / pneumology', 'total_hcps',\n",
    "                  'population', 'Pediatrician']\n",
    "\n",
    "for f in feats_to_group:\n",
    "    # groups are computed using training data\n",
    "    groups = np.quantile(train_regions_data[f], q=[0, 0.25, 0.5, 0.75])\n",
    "    groups = np.insert(groups, 0, 0)\n",
    "    groups = np.insert(groups, len(groups), np.inf)\n",
    "    train_regions_data[f'{f}_group'] = pd.cut(train_regions_data[f], groups)\n",
    "    val_regions_data[f'{f}_group'] = pd.cut(val_regions_data[f], groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e33eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the average of these groups is computed using the training dataset\n",
    "averages = dict()\n",
    "for f in feats_to_group:\n",
    "    x = (train_sales\n",
    "         .merge(train_regions_data)\n",
    "         .groupby([f'{f}_group'], as_index=False)\n",
    "         [['sales']]\n",
    "         .mean())\n",
    "    x.rename(columns={'sales': f'{f}_mean_sales'}, inplace=True)\n",
    "    averages[f] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f52217ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding average to train\n",
    "train_feats = train_regions_data\n",
    "for f in feats_to_group:\n",
    "    train_feats = train_feats.merge(averages[f], on=f'{f}_group')\n",
    "train_feats = train_feats.merge(train_sales)\n",
    "columns = ['month', 'brand', 'region'] + [c for c in train_feats.columns if c.endswith('mean_sales')]\n",
    "train_feats = train_feats[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d434926b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding average to val\n",
    "val_feats = val_regions_data\n",
    "for f in feats_to_group:\n",
    "    val_feats = val_feats.merge(averages[f], on=f'{f}_group')\n",
    "val_feats = val_feats.merge(val_sales)\n",
    "columns = ['month', 'brand', 'region'] + [c for c in val_feats.columns if c.endswith('mean_sales')]\n",
    "val_feats = val_feats[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d270be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats.to_csv('../data/features/train_group_features_for_validation.csv')\n",
    "val_feats.to_csv('../data/features/test_group_features_for_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4aa95a",
   "metadata": {},
   "source": [
    "## 2.2 - datasets for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f970cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val_regions_data = pd.concat([train_regions_data, val_regions_data])\n",
    "train_and_val_sales = pd.concat([train_sales, val_sales])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3175f8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here the groups are generated for different features \n",
    "feats_to_group = ['pci16', 'pci18', 'Internal medicine / pneumology', 'total_hcps',\n",
    "                  'population', 'Pediatrician']\n",
    "\n",
    "for f in feats_to_group:\n",
    "    # groups are computed using training data\n",
    "    groups = np.quantile(train_and_val_regions_data[f], q=[0, 0.25, 0.5, 0.75])\n",
    "    groups = np.insert(groups, 0, 0)\n",
    "    groups = np.insert(groups, len(groups), np.inf)\n",
    "    train_and_val_regions_data[f'{f}_group'] = pd.cut(train_and_val_regions_data[f], groups)\n",
    "    test_regions_data[f'{f}_group'] = pd.cut(test_regions_data[f], groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a895b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the average of these groups is computed using the training dataset\n",
    "averages = dict()\n",
    "for f in feats_to_group:\n",
    "    x = (train_and_val_sales\n",
    "         .merge(train_and_val_regions_data)\n",
    "         .groupby([f'{f}_group'], as_index=False)\n",
    "         [['sales']]\n",
    "         .mean())\n",
    "    x.rename(columns={'sales': f'{f}_mean_sales'}, inplace=True)\n",
    "    averages[f] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b6b6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding average to train\n",
    "train_feats = train_and_val_regions_data\n",
    "for f in feats_to_group:\n",
    "    train_feats = train_feats.merge(averages[f], on=f'{f}_group')\n",
    "train_feats = train_feats.merge(train_and_val_sales)\n",
    "columns = ['month', 'brand', 'region'] + [c for c in train_feats.columns if c.endswith('mean_sales')]\n",
    "train_feats = train_feats[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd7cd3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding average to test\n",
    "test_feats = test_regions_data\n",
    "for f in feats_to_group:\n",
    "    test_feats = test_feats.merge(averages[f], on=f'{f}_group')\n",
    "test_feats = test_feats.merge(val_sales)\n",
    "columns = ['month', 'brand', 'region'] + [c for c in test_feats.columns if c.endswith('mean_sales')]\n",
    "test_feats = test_feats[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77f77072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats.to_csv('../data/features/train_group_features_for_test.csv')\n",
    "test_feats.to_csv('../data/features/test_group_features_for_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f4ecc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'brand', 'region', 'pci16_mean_sales', 'pci18_mean_sales',\n",
       "       'Internal medicine / pneumology_mean_sales', 'total_hcps_mean_sales',\n",
       "       'population_mean_sales', 'Pediatrician_mean_sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84ce03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63623b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
