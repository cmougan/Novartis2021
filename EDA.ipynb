{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8702ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8917a63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/Desktop/Novartis2021/models\n"
     ]
    }
   ],
   "source": [
    "cd models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcce491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d13ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from sktools import QuantileEncoder\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from metrics.metric_participants import ComputeMetrics, print_metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sktools import IsEmptyExtractor\n",
    "from lightgbm import LGBMRegressor\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklego.preprocessing import ColumnSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sktools import QuantileEncoder\n",
    "from eda.checker import check_train_test\n",
    "from tools.postprocessing import postprocess_predictions\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "sales_train = pd.read_csv(\"../data/data_raw/sales_train.csv\")\n",
    "df_full = pd.read_csv(\"../data/split.csv\")\n",
    "df_region = pd.read_csv(\"../data/data_raw/regions.csv\")\n",
    "regions_hcps = pd.read_csv(\"../data/data_raw/regions_hcps.csv\")\n",
    "activity_features = pd.read_csv(\"../data/features/activity_features.csv\")\n",
    "brands_3_12 = pd.read_csv(\"../data/features/brand_3_12_market_features_lagged.csv\")\n",
    "rte_basic = pd.read_csv(\"../data/features/rte_features_v2.csv\").drop(\n",
    "    columns=[\"sales\", \"validation\"]\n",
    ")\n",
    "\n",
    "market_size = pd.read_csv(\"../data/market_size.csv\")\n",
    "\n",
    "# For reproducibility\n",
    "random.seed(0)\n",
    "VAL_SIZE = 38\n",
    "SUBMISSION_NAME = \"linear_model_simple\"\n",
    "RETRAIN = True\n",
    "\n",
    "# %% Training weights\n",
    "market_size = market_size.assign(weight=lambda x: 100 / x[\"sales\"]).rename(\n",
    "    columns={\"sales\": \"market_size\"}\n",
    ")\n",
    "\n",
    "market_size\n",
    "\n",
    "# %% Add region data\n",
    "df_feats = df_full.merge(df_region, on=\"region\", how=\"left\")\n",
    "df_feats = pd.merge(left=df_feats, right=regions_hcps, how=\"left\", on=\"region\")\n",
    "df_feats = df_feats.merge(\n",
    "    activity_features, on=[\"month\", \"region\", \"brand\"], how=\"left\"\n",
    ")\n",
    "df_feats = df_feats.merge(rte_basic, on=[\"month\", \"region\", \"brand\"], how=\"left\")\n",
    "df_feats = df_feats.merge(brands_3_12, on=[\"month\", \"region\"], how=\"left\")\n",
    "df_feats[\"whichBrand\"] = np.where(df_feats.brand == \"brand_1\", 1, 0)\n",
    "\n",
    "df_feats = df_feats.merge(market_size, on=\"region\", how=\"left\")\n",
    "\n",
    "df_feats[\"month_brand\"] = df_feats.month + \"_\" + df_feats.brand\n",
    "\n",
    "df_feats[\"market_estimation\"] = (\n",
    "    df_feats.sales_brand_12_market * df_feats.sales_brand_3\n",
    ") / df_feats.sales_brand_3_market\n",
    "\n",
    "df_feats.loc[df_feats.brand == \"brand_1\", \"market_estimation\"] = (\n",
    "    0.75 * df_feats.loc[df_feats.brand == \"brand_1\", \"market_estimation\"]\n",
    ")\n",
    "df_feats.loc[df_feats.brand == \"brand_2\", \"market_estimation\"] = (\n",
    "    0.25 * df_feats.loc[df_feats.brand == \"brand_2\", \"market_estimation\"]\n",
    ")\n",
    "\n",
    "# drop sum variables\n",
    "cols_to_drop = [\"region\", \"sales\", \"validation\", \"market_size\", \"weight\"]\n",
    "\n",
    "# %% Split train val test\n",
    "X_train = df_feats.query(\"validation == 0\").drop(columns=cols_to_drop)\n",
    "y_train = df_feats.query(\"validation == 0\").sales\n",
    "weights_train = df_feats.query(\"validation == 0\").weight\n",
    "\n",
    "X_val = df_feats.query(\"validation == 1\").drop(columns=cols_to_drop)\n",
    "y_val = df_feats.query(\"validation == 1\").sales\n",
    "\n",
    "X_full = df_feats.query(\"validation.notnull()\", engine=\"python\").drop(\n",
    "    columns=cols_to_drop\n",
    ")\n",
    "y_full = df_feats.query(\"validation.notnull()\", engine=\"python\").sales\n",
    "weights_full = df_feats.query(\"validation.notnull()\", engine=\"python\").weight\n",
    "\n",
    "X_test = df_feats.query(\"validation.isnull()\", engine=\"python\").drop(\n",
    "    columns=cols_to_drop\n",
    ")\n",
    "y_test = df_feats.query(\"validation.isnull()\", engine=\"python\").sales\n",
    "\n",
    "check_train_test(X_train, X_val)\n",
    "check_train_test(X_train, X_test, threshold=0.3)\n",
    "check_train_test(X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1a56a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brand'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    'whichBrand',\n",
    "    'count',\n",
    "    'inverse_tier_f2f',\n",
    "    'hcp_distinct_Internal medicine / pneumology',\n",
    "    'sales_brand_3',\n",
    "    'sales_brand_3_market',\n",
    "    'sales_brand_12_market',\n",
    "    'month_brand',\n",
    "    'month',\n",
    "    'brand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4450d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {}\n",
    "feats[0.5] = [\n",
    "    'whichBrand',\n",
    "    \"sales_brand_12_marketshift0\",\n",
    "    \"sales_brand_3\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"month_brand\",\n",
    "    \"null_tiers_phone\",\n",
    "    \"null_tiers\",\n",
    "    \"Pediatrician\",\n",
    "    \"sales_brand_3_marketshift-4\",\n",
    "    \"sales_brand_3shift-10\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology_3m\",\n",
    "    \"Internal medicine and general practicioner\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_Pediatrician\",\n",
    "    \"sales_brand_12_marketshift4\",\n",
    "    \"no. clicks\",\n",
    "    \"no. openings_Internal medicine / pneumology\",\n",
    "    \"hcp_distinct\",\n",
    "]\n",
    "feats[0.1] = [\n",
    "    'whichBrand',\n",
    "    \"month\",\n",
    "    \"count\",\n",
    "    \"month_brand\",\n",
    "    \"count_f2f\",\n",
    "    \"sales_brand_12_marketshift0\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"sales_brand_3_market_per_region\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_marketshift0\",\n",
    "]\n",
    "feats[0.9] = [\n",
    "    'whichBrand',\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"sales_brand_12_marketshift0\",\n",
    "    \"month_brand\",\n",
    "    \"tier_openings_Internal medicine / pneumology\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology_3m\",\n",
    "    \"no. openings_Pediatrician\",\n",
    "    \"inverse_tier_Pediatrician\",\n",
    "    \"no. openings_Internal medicine / pneumology\",\n",
    "    \"no. clicks_Internal medicine\",\n",
    "    \"hcp_distinct\",\n",
    "    \"no. clicks_product_related\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c4fe1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {}\n",
    "feats[0.5] = [\n",
    "    \"whichBrand\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_market\",\n",
    "    \"sales_brand_12_market\",\n",
    "    \"month_brand\",\n",
    "    \"month_1\",\n",
    "    \"month_2\",\n",
    "    \"month_3\",\n",
    "    \"month_4\",\n",
    "    \"month_5\",\n",
    "    \"month_6\",\n",
    "    \"month_7\",\n",
    "    \"month_8\",\n",
    "    \"month_9\",\n",
    "    \"month_10\",\n",
    "    \"month_11\",\n",
    "    \"month_12\",\n",
    "    \"month_13\",\n",
    "    \"month_14\",\n",
    "    'market_estimation'\n",
    "]\n",
    "feats[0.1] = [\n",
    "    \"whichBrand\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_market\",\n",
    "    \"sales_brand_12_market\",\n",
    "    \"month_brand\",\n",
    "    \"count_f2f\",\n",
    "    \"month_1\",\n",
    "    \"month_2\",\n",
    "    \"month_3\",\n",
    "    \"month_4\",\n",
    "    \"month_5\",\n",
    "    \"month_6\",\n",
    "    \"month_7\",\n",
    "    \"month_8\",\n",
    "    \"month_9\",\n",
    "    \"month_10\",\n",
    "    \"month_11\",\n",
    "    \"month_12\",\n",
    "    \"month_13\",\n",
    "    \"month_14\",\n",
    "    'market_estimation'\n",
    "]\n",
    "feats[0.9] = [\n",
    "    \"whichBrand\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"tier_openings_Internal medicine / pneumology\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_market\",\n",
    "    \"sales_brand_12_market\",\n",
    "    \"month_brand\",\n",
    "    \"month_1\",\n",
    "    \"month_2\",\n",
    "    \"month_3\",\n",
    "    \"month_4\",\n",
    "    \"month_5\",\n",
    "    \"month_6\",\n",
    "    \"month_7\",\n",
    "    \"month_8\",\n",
    "    \"month_9\",\n",
    "    \"month_10\",\n",
    "    \"month_11\",\n",
    "    \"month_12\",\n",
    "    \"month_13\",\n",
    "    \"month_14\",\n",
    "    'market_estimation'\n",
    "]\n",
    "\n",
    "encoder = {}\n",
    "encoder[0.1] = QuantileEncoder(cols=[\"month_brand\"],quantile=0.2)\n",
    "encoder[0.5] = TargetEncoder(cols=[\"month_brand\"])\n",
    "encoder[0.9] = QuantileEncoder(cols=[\"month_brand\"],quantile=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6806013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.5\n",
      "Quantile: 0.1\n",
      "Quantile: 0.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "models = {}\n",
    "pipes = {}\n",
    "train_preds = {}\n",
    "val_preds = {}\n",
    "test_preds = {}\n",
    "\n",
    "for quantile in [0.5, 0.1, 0.9]:\n",
    "\n",
    "    print(\"Quantile:\", quantile)\n",
    "    models[quantile] = QuantileRegressor(\n",
    "        quantile=quantile,\n",
    "        alpha=0,\n",
    "        solver=\"highs-ds\"\n",
    "    )\n",
    "\n",
    "    pipes[quantile] = Pipeline(\n",
    "        [   ('ohe',OneHotEncoder(cols = ['month'])),\n",
    "            (\"te\",encoder[quantile]),\n",
    "            (\"selector\", ColumnSelector(columns=feats[quantile])),\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)), \n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"qr\", models[quantile])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit cv model\n",
    "    pipes[quantile].fit(X_train, y_train)\n",
    "    # , qr__sample_weight=weights_train)\n",
    "\n",
    "    train_preds[quantile] = pipes[quantile].predict(X_train)\n",
    "    val_preds[quantile] = pipes[quantile].predict(X_val)\n",
    "\n",
    "    if RETRAIN:\n",
    "        pipes[quantile].fit(X_full, y_full)\n",
    "        # , qr__sample_weight=weights_full)\n",
    "    test_preds[quantile] = pipes[quantile].predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c560de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.58, interval: 179.15\n",
      "Accuracy: 32.56, interval: 147.80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32.55885252772722, 147.80258792681033)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Postprocess\n",
    "train_preds_post = postprocess_predictions(train_preds)\n",
    "val_preds_post = postprocess_predictions(val_preds)\n",
    "test_preds_post = postprocess_predictions(test_preds)\n",
    "\n",
    "# %% Train prediction\n",
    "train_preds_df = (\n",
    "    df_feats.query(\"validation == 0\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=train_preds_post[0.5])\n",
    "    .assign(lower=train_preds_post[0.1])\n",
    "    .assign(upper=train_preds_post[0.9])\n",
    ")\n",
    "\n",
    "ground_truth_train = df_feats.query(\"validation == 0\").loc[\n",
    "    :, [\"month\", \"region\", \"brand\", \"sales\"]\n",
    "]\n",
    "\n",
    "print_metrics(train_preds_df, sales_train, ground_truth_train)\n",
    "\n",
    "# %% Validation prediction\n",
    "val_preds_df = (\n",
    "    df_feats.query(\"validation == 1\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=val_preds_post[0.5])\n",
    "    .assign(lower=val_preds_post[0.1])\n",
    "    .assign(upper=val_preds_post[0.9])\n",
    ")\n",
    "\n",
    "ground_truth_val = df_feats.query(\"validation == 1\").loc[\n",
    "    :, [\"month\", \"region\", \"brand\", \"sales\"]\n",
    "]\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "print_metrics(val_preds_df, sales_train, ground_truth_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ccb171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ccf092",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best\n",
    "32.55, 147.80\n",
    "Original\n",
    "34.31, 152.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db57789",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feats, OHE, Month, QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41b3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "val_preds_df.to_csv(f\"../data/validation/{SUBMISSION_NAME}_val.csv\", index=False)\n",
    "\n",
    "\n",
    "# %% Test prediction\n",
    "test_preds_df = (\n",
    "    df_feats.query(\"validation.isnull()\", engine=\"python\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=test_preds_post[0.5])\n",
    "    .assign(lower=test_preds_post[0.1])\n",
    "    .assign(upper=test_preds_post[0.9])\n",
    ")\n",
    "\n",
    "test_preds_df.to_csv(f\"../submissions/{SUBMISSION_NAME}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4230b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd071e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(pipes[0.5].named_steps[\"lgb\"])\n",
    "shap_values = explainer(\n",
    "    pd.DataFrame(pipe[:-1].transform(X_train), columns=X_train.columns)\n",
    ")\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a4f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34552b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Train prediction\n",
    "train_preds_df = (\n",
    "    df_feats.query(\"validation == 0\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=train_preds[0.5])\n",
    "    .assign(lower=train_preds[0.1].clip(0))\n",
    "    .assign(upper=train_preds[0.9])\n",
    ")\n",
    "\n",
    "ground_truth_train = df_feats.query(\"validation == 0\").loc[\n",
    "    :, [\"month\", \"region\", \"brand\", \"sales\"]\n",
    "]\n",
    "\n",
    "print(ComputeMetrics(train_preds_df, sales_train, ground_truth_train))\n",
    "\n",
    "# %% Validation prediction\n",
    "val_preds_df = (\n",
    "    df_feats.query(\"validation == 1\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=val_preds[0.5])\n",
    "    .assign(lower=val_preds[0.1].clip(0))\n",
    "    .assign(upper=val_preds[0.9])\n",
    ")\n",
    "\n",
    "ground_truth_val = df_feats.query(\"validation == 1\").loc[\n",
    "    :, [\"month\", \"region\", \"brand\", \"sales\"]\n",
    "]\n",
    "\n",
    "print(ComputeMetrics(val_preds_df, sales_train, ground_truth_val))\n",
    "\n",
    "# %%\n",
    "val_preds_df.to_csv(f\"../data/validation/{SUBMISSION_NAME}.csv\", index=False)\n",
    "\n",
    "\n",
    "# %% Test prediction\n",
    "test_preds_df = (\n",
    "    df_feats.query(\"validation.isnull()\", engine=\"python\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=test_preds[0.5])\n",
    "    .assign(lower=test_preds[0.1].clip(0))\n",
    "    .assign(upper=test_preds[0.9])\n",
    ")\n",
    "\n",
    "test_preds_df.to_csv(f\"../submissions/{SUBMISSION_NAME}.csv\", index=False)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ed8df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.5\n",
      "Quantile: 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-899f2516c064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# Fit cv model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mpipes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;31m# , qr__sample_weight=weights_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/novartis/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/novartis/lib/python3.8/site-packages/sklearn/linear_model/_quantile.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mb_eq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         result = linprog(\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mA_eq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_eq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/novartis/lib/python3.8/site-packages/scipy/optimize/_linprog.py\u001b[0m in \u001b[0;36mlinprog\u001b[0;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0)\u001b[0m\n\u001b[1;32m    601\u001b[0m                          'highs': None}\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         sol = _linprog_highs(lp, solver=highs_solvers[meth],\n\u001b[0m\u001b[1;32m    604\u001b[0m                              **solver_options)\n\u001b[1;32m    605\u001b[0m         sol['status'], sol['message'] = (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/novartis/lib/python3.8/site-packages/scipy/optimize/_linprog_highs.py\u001b[0m in \u001b[0;36m_linprog_highs\u001b[0;34m(lp, solver, time_limit, presolve, disp, maxiter, dual_feasibility_tolerance, primal_feasibility_tolerance, ipm_optimality_tolerance, simplex_dual_edge_weight_strategy, **unknown_options)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_inf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     res = _highs_wrapper(c, A.indptr, A.indices, A.data, lhs, rhs,\n\u001b[0m\u001b[1;32m    375\u001b[0m                          lb, ub, options)\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% Imports\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from metrics.metric_participants import ComputeMetrics, print_metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sktools import IsEmptyExtractor\n",
    "from lightgbm import LGBMRegressor\n",
    "from category_encoders import OneHotEncoder\n",
    "from sktools import QuantileEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklego.preprocessing import ColumnSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from tools.postprocessing import clip_first_month\n",
    "\n",
    "from eda.checker import check_train_test\n",
    "from tools.postprocessing import postprocess_predictions\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "sales_train = pd.read_csv(\"../data/data_raw/sales_train.csv\")\n",
    "df_full = pd.read_csv(\"../data/split.csv\")\n",
    "df_region = pd.read_csv(\"../data/data_raw/regions.csv\")\n",
    "regions_hcps = pd.read_csv(\"../data/data_raw/regions_hcps.csv\")\n",
    "activity_features = pd.read_csv(\"../data/features/activity_features.csv\")\n",
    "brands_3_12 = pd.read_csv(\"../data/features/brand_3_12_market_features_lagged.csv\")\n",
    "rte_basic = pd.read_csv(\"../data/features/rte_basic_features.csv\").drop(\n",
    "    columns=[\"sales\", \"validation\"]\n",
    ")\n",
    "\n",
    "market_size = pd.read_csv(\"../data/market_size.csv\")\n",
    "\n",
    "# For reproducibility\n",
    "random.seed(0)\n",
    "VAL_SIZE = 38\n",
    "SUBMISSION_NAME = \"linear_model_simple\"\n",
    "RETRAIN = True\n",
    "\n",
    "# %% Training weights\n",
    "market_size = market_size.assign(weight=lambda x: 100 / x[\"sales\"]).rename(\n",
    "    columns={\"sales\": \"market_size\"}\n",
    ")\n",
    "\n",
    "market_size\n",
    "\n",
    "# %% Add region data\n",
    "df_feats = df_full.merge(df_region, on=\"region\", how=\"left\")\n",
    "df_feats = pd.merge(left=df_feats, right=regions_hcps, how=\"left\", on=\"region\")\n",
    "df_feats = df_feats.merge(\n",
    "    activity_features, on=[\"month\", \"region\", \"brand\"], how=\"left\"\n",
    ")\n",
    "df_feats = df_feats.merge(rte_basic, on=[\"month\", \"region\", \"brand\"], how=\"left\")\n",
    "df_feats = df_feats.merge(brands_3_12, on=[\"month\", \"region\"], how=\"left\")\n",
    "df_feats[\"whichBrand\"] = np.where(df_feats.brand == \"brand_1\", 1, 0)\n",
    "\n",
    "df_feats = df_feats.merge(market_size, on=\"region\", how=\"left\")\n",
    "\n",
    "df_feats[\"month_brand\"] = df_feats.month + \"_\" + df_feats.brand\n",
    "\n",
    "# drop sum variables\n",
    "cols_to_drop = [\"region\", \"sales\", \"validation\", \"market_size\", \"weight\"]\n",
    "\n",
    "# %% Split train val test\n",
    "X_train = df_feats.query(\"validation == 0\").drop(columns=cols_to_drop)\n",
    "y_train = df_feats.query(\"validation == 0\").sales\n",
    "weights_train = df_feats.query(\"validation == 0\").weight\n",
    "\n",
    "X_val = df_feats.query(\"validation == 1\").drop(columns=cols_to_drop)\n",
    "y_val = df_feats.query(\"validation == 1\").sales\n",
    "\n",
    "X_full = df_feats.query(\"validation.notnull()\", engine=\"python\").drop(\n",
    "    columns=cols_to_drop\n",
    ")\n",
    "y_full = df_feats.query(\"validation.notnull()\", engine=\"python\").sales\n",
    "weights_full = df_feats.query(\"validation.notnull()\", engine=\"python\").weight\n",
    "\n",
    "X_test = df_feats.query(\"validation.isnull()\", engine=\"python\").drop(\n",
    "    columns=cols_to_drop\n",
    ")\n",
    "y_test = df_feats.query(\"validation.isnull()\", engine=\"python\").sales\n",
    "\n",
    "check_train_test(X_train, X_val)\n",
    "check_train_test(X_train, X_test, threshold=0.3)\n",
    "check_train_test(X_val, X_test)\n",
    "# %%\n",
    "feats = {}\n",
    "feats[0.5] = [\n",
    "    \"whichBrand\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_market\",\n",
    "    \"sales_brand_12_market\",\n",
    "    \"month_brand\",\n",
    "    \"month_1\",\n",
    "    \"month_2\",\n",
    "    \"month_3\",\n",
    "    \"month_4\",\n",
    "    \"month_5\",\n",
    "    \"month_6\",\n",
    "    \"month_7\",\n",
    "    \"month_8\",\n",
    "    \"month_9\",\n",
    "    \"month_10\",\n",
    "    \"month_11\",\n",
    "    \"month_12\",\n",
    "    \"month_13\",\n",
    "    \"month_14\",\n",
    "]\n",
    "feats[0.1] = [\n",
    "    \"whichBrand\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_market\",\n",
    "    \"sales_brand_12_market\",\n",
    "    \"month_brand\",\n",
    "    \"count_f2f\",\n",
    "    \"month_1\",\n",
    "    \"month_2\",\n",
    "    \"month_3\",\n",
    "    \"month_4\",\n",
    "    \"month_5\",\n",
    "    \"month_6\",\n",
    "    \"month_7\",\n",
    "    \"month_8\",\n",
    "    \"month_9\",\n",
    "    \"month_10\",\n",
    "    \"month_11\",\n",
    "    \"month_12\",\n",
    "    \"month_13\",\n",
    "    \"month_14\",\n",
    "]\n",
    "feats[0.9] = [\n",
    "    \"whichBrand\",\n",
    "    \"count\",\n",
    "    \"inverse_tier_f2f\",\n",
    "    \"hcp_distinct_Internal medicine / pneumology\",\n",
    "    \"tier_openings_Internal medicine / pneumology\",\n",
    "    \"sales_brand_3\",\n",
    "    \"sales_brand_3_market\",\n",
    "    \"sales_brand_12_market\",\n",
    "    \"month_brand\",\n",
    "    \"month_1\",\n",
    "    \"month_2\",\n",
    "    \"month_3\",\n",
    "    \"month_4\",\n",
    "    \"month_5\",\n",
    "    \"month_6\",\n",
    "    \"month_7\",\n",
    "    \"month_8\",\n",
    "    \"month_9\",\n",
    "    \"month_10\",\n",
    "    \"month_11\",\n",
    "    \"month_12\",\n",
    "    \"month_13\",\n",
    "    \"month_14\",\n",
    "]\n",
    "\n",
    "encoder = {}\n",
    "encoder[0.1] = QuantileEncoder(cols=[\"month_brand\"], quantile=0.2)\n",
    "encoder[0.5] = TargetEncoder(cols=[\"month_brand\"])\n",
    "encoder[0.9] = QuantileEncoder(cols=[\"month_brand\"], quantile=0.8)\n",
    "# %%\n",
    "models = {}\n",
    "pipes = {}\n",
    "train_preds = {}\n",
    "val_preds = {}\n",
    "test_preds = {}\n",
    "\n",
    "for quantile in [0.5, 0.1, 0.9]:\n",
    "\n",
    "    print(\"Quantile:\", quantile)\n",
    "    models[quantile] = QuantileRegressor(quantile=quantile, alpha=0, solver=\"highs-ds\")\n",
    "\n",
    "    pipes[quantile] = Pipeline(\n",
    "        [\n",
    "            (\"ohe\", OneHotEncoder(cols=[\"month\"])),\n",
    "            (\"te\", encoder[quantile]),\n",
    "            (\"selector\", ColumnSelector(columns=feats[quantile])),\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"qr\", models[quantile]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit cv model\n",
    "    pipes[quantile].fit(X_train, y_train)\n",
    "    # , qr__sample_weight=weights_train)\n",
    "\n",
    "    train_preds[quantile] = pipes[quantile].predict(X_train)\n",
    "    val_preds[quantile] = pipes[quantile].predict(X_val)\n",
    "\n",
    "    if RETRAIN:\n",
    "        pipes[quantile].fit(X_full, y_full)\n",
    "        # , qr__sample_weight=weights_full)\n",
    "    test_preds[quantile] = pipes[quantile].predict(X_test)\n",
    "\n",
    "# %% Postprocess\n",
    "train_preds_post = postprocess_predictions(train_preds)\n",
    "val_preds_post = postprocess_predictions(val_preds)\n",
    "test_preds_post = postprocess_predictions(test_preds)\n",
    "\n",
    "# %% Train prediction\n",
    "train_preds_df = (\n",
    "    df_feats.query(\"validation == 0\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=train_preds_post[0.5])\n",
    "    .assign(lower=train_preds_post[0.1])\n",
    "    .assign(upper=train_preds_post[0.9])\n",
    "    .assign(clip_first_month)\n",
    ")\n",
    "\n",
    "ground_truth_train = df_feats.query(\"validation == 0\").loc[\n",
    "    :, [\"month\", \"region\", \"brand\", \"sales\"]\n",
    "]\n",
    "\n",
    "print_metrics(train_preds_df, sales_train, ground_truth_train)\n",
    "\n",
    "# %% Validation prediction\n",
    "val_preds_df = (\n",
    "    df_feats.query(\"validation == 1\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=val_preds_post[0.5])\n",
    "    .assign(lower=val_preds_post[0.1])\n",
    "    .assign(upper=val_preds_post[0.9])\n",
    "    .assign(clip_first_month)\n",
    ")\n",
    "\n",
    "ground_truth_val = df_feats.query(\"validation == 1\").loc[\n",
    "    :, [\"month\", \"region\", \"brand\", \"sales\"]\n",
    "]\n",
    "\n",
    "print_metrics(val_preds_df, sales_train, ground_truth_val)\n",
    "\n",
    "# %%\n",
    "val_preds_df.to_csv(f\"../data/validation/{SUBMISSION_NAME}_val.csv\", index=False)\n",
    "\n",
    "\n",
    "# %% Test prediction\n",
    "test_preds_df = (\n",
    "    df_feats.query(\"validation.isnull()\", engine=\"python\")\n",
    "    .loc[:, [\"month\", \"region\", \"brand\"]]\n",
    "    .assign(sales=test_preds_post[0.5])\n",
    "    .assign(lower=test_preds_post[0.1])\n",
    "    .assign(upper=test_preds_post[0.9])\n",
    "    .assign(clip_first_month)\n",
    ")\n",
    "\n",
    "test_preds_df.to_csv(f\"../submissions/{SUBMISSION_NAME}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6ebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novartis",
   "language": "python",
   "name": "novartis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
